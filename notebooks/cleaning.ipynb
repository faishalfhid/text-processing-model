{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b90381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca3903a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = path.abspath('../') + \"/datasets/\"\n",
    "model_path = path.abspath('../') + \"/models/\"\n",
    "data = pd.read_csv(dataset_path + 'spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21680428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    # case folding\n",
    "    text = text.lower()\n",
    "\n",
    "    # replace numbers with token\n",
    "    text = re.sub(r'\\d+', ' <NUM> ', text)\n",
    "\n",
    "    # remove punctuation (tapi jangan spasi)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # stopword removal (tapi jangan terlalu agresif)\n",
    "    factory = StopWordRemoverFactory()\n",
    "    stopwords = set(factory.get_stop_words())\n",
    "    words = text.split()\n",
    "    text = \" \".join([word for word in words if word not in stopwords])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e763a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Pesan'] = data['Pesan'].astype(str).apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42d938c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Le = LabelEncoder()\n",
    "data['Kategori'] = Le.fit_transform(data['Kategori'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fb82099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping label: {'ham': np.int64(0), 'spam': np.int64(1)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Mapping label:\", dict(zip(Le.classes_, Le.transform(Le.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8605c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2)  # min_df=2 untuk buang kata langka\n",
    "X = vectorizer.fit_transform(data[\"Pesan\"])\n",
    "y = data[\"Kategori\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fcd86e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open(model_path + \"vectorizer_2.pkl\", \"wb\"))\n",
    "pickle.dump(Le, open(model_path + \"label_encoder_2.pkl\", \"wb\"))\n",
    "data.to_csv(dataset_path + \"cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
